{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy  <font>AutoML for Model Selection</font> Model Package from AWS Marketplace \n",
    "\n",
    "\n",
    "#### <font> The solution runs multiple ML models on the user data and will evalute them on the specified evaluation criteria.</font>\n",
    "\n",
    "<font>This solution runs several classification and regression machine learning models on the input data. The user can provide the specific models and the evaluation metric to use in a separate config file. This will simplify the task of model building for a data scientist where in the user will only have to specify select few parameter to find the best model for the data set.</font>\n",
    "\n",
    "This sample notebook shows you how to deploy <font color='red'>[AutoML for Model Selection](https://aws.amazon.com/marketplace/pp/prodview-cbcawjzo64bq2)</font> using Amazon SageMaker.\n",
    "\n",
    "> **Note**: This is a reference notebook and it cannot run unless you make changes suggested in the notebook.\n",
    "\n",
    "#### Pre-requisites:\n",
    "1. **Note**: This notebook contains elements which render correctly in Jupyter interface. Open this notebook from an Amazon SageMaker Notebook Instance or Amazon SageMaker Studio.\n",
    "1. Ensure that IAM role used has **AmazonSageMakerFullAccess**\n",
    "1. To deploy this ML model successfully, ensure that:\n",
    "    1. Either your IAM role has these three permissions and you have authority to make AWS Marketplace subscriptions in the AWS account used: \n",
    "        1. **aws-marketplace:ViewSubscriptions**\n",
    "        1. **aws-marketplace:Unsubscribe**\n",
    "        1. **aws-marketplace:Subscribe**  \n",
    "    2. or your AWS account has a subscription to <font color='red'>[AutoML for Model Selection](https://aws.amazon.com/marketplace/pp/prodview-cbcawjzo64bq2)</font>. If so, skip step: [Subscribe to the model package](http:\\\\)\n",
    "\n",
    "#### Contents:\n",
    "1. [Subscribe to the model package](#1.-Subscribe-to-the-model-package)\n",
    "2. [Create an endpoint and perform real-time inference](#2.-Create-an-endpoint-and-perform-real-time-inference)\n",
    "   1. [Create an endpoint](#A.-Create-an-endpoint)\n",
    "   2. [Create input payload](#B.-Create-input-payload)\n",
    "   3. [Perform real-time inference](#C.-Perform-real-time-inference)\n",
    "   4. [Visualize output](#D.-Visualize-output)\n",
    "   5. [Delete the endpoint](#E.-Delete-the-endpoint)\n",
    "3. [Perform batch inference](#3.-Perform-batch-inference) \n",
    "4. [Clean-up](#4.-Clean-up)\n",
    "    1. [Delete the model](#A.-Delete-the-model)\n",
    "    2. [Unsubscribe to the listing (optional)](#B.-Unsubscribe-to-the-listing-(optional))\n",
    "    \n",
    "\n",
    "#### Usage instructions\n",
    "You can run this notebook one cell at a time (By using Shift+Enter for running a cell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Subscribe to the model package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To subscribe to the model package:\n",
    "1. Open the model package listing page <font color='red'> [AutoML for Model Selection](https://aws.amazon.com/marketplace/pp/prodview-cbcawjzo64bq2).</font>\n",
    "1. On the AWS Marketplace listing, click on the **Continue to subscribe** button.\n",
    "1. On the **Subscribe to this software** page, review and click on **\"Accept Offer\"** if you and your organization agrees with EULA, pricing, and support terms. \n",
    "1. Once you click on **Continue to configuration button** and then choose a **region**, you will see a **Product Arn** displayed. This is the model package ARN that you need to specify while creating a deployable model using Boto3. Copy the ARN corresponding to your region and specify the same in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn='your-arn-number'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> For Seller to update: Add all necessary imports in following cell, \n",
    "If you need specific packages to be installed, # try to provide them in this section, in a separate cell. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"sagemaker\"\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json \n",
    "import uuid\n",
    "from sagemaker import ModelPackage\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "#from urllib.parse import urlparse\n",
    "import boto3\n",
    "from IPython.display import Image\n",
    "from PIL import Image as ImageEdit\n",
    "#import urllib.request\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sagemaker-us-east-2-786796469737'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()\n",
    "\n",
    "bucket=sagemaker_session.default_bucket()\n",
    "bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create an endpoint and perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to understand how real-time inference with Amazon SageMaker works, see [Documentation](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-hosting.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>For Seller to update: update values for four variables in following cell. \n",
    "Specify a model/endpoint name using only alphanumeric characters. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='paceml-automl'\n",
    "\n",
    "content_type='application/zip'\n",
    "\n",
    "real_time_inference_instance_type='ml.m5.xlarge'\n",
    "batch_transform_inference_instance_type='ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Create an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "\n",
    "def predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session,content_type)\n",
    "\n",
    "#create a deployable model from the model package.\n",
    "model = ModelPackage(role=role,\n",
    "                    model_package_arn=model_package_arn,\n",
    "                    sagemaker_session=sagemaker_session,\n",
    "                    predictor_cls=predict_wrapper)\n",
    "\n",
    "#Deploy the model\n",
    "predictor = model.deploy(1, real_time_inference_instance_type, endpoint_name=model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once endpoint has been created, you would be able to perform real-time inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Create input payload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>For Seller to update: Add code snippet here that reads the input from 'data/input/real-time/' directory \n",
    "and converts it into format expected by the endpoint.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "import pandas as pd\n",
    "file_name = './data/input/real-time/sample_data_automl.zip'\n",
    "def read_zip_file(zipfile_obj):\n",
    "    try:\n",
    "        file_names = zipfile_obj.namelist()\n",
    "        csv_file_name = [f for f in file_names if 'csv' in f][0]\n",
    "        json_file_name = [f for f in file_names if 'json' in f][0]\n",
    "        json_file_content = json.load(zipfile_obj.open(json_file_name))\n",
    "        data = pd.read_csv(zipfile_obj.open(csv_file_name))\n",
    "        return data, json_file_content\n",
    "    except Exception as e:\n",
    "        print('There was some error:', str(e))\n",
    "    return None, None\n",
    "\n",
    "zipfile_obj = ZipFile(file_name)\n",
    "data_df, config_dict = read_zip_file(zipfile_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "5        12.45         15.70           82.57      477.1          0.12780   \n",
      "6        18.25         19.98          119.60     1040.0          0.09463   \n",
      "7        13.71         20.83           90.20      577.9          0.11890   \n",
      "8        13.00         21.82           87.50      519.8          0.12730   \n",
      "9        12.46         24.04           83.97      475.9          0.11860   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760         0.30010              0.14710         0.2419   \n",
      "1           0.07864         0.08690              0.07017         0.1812   \n",
      "2           0.15990         0.19740              0.12790         0.2069   \n",
      "3           0.28390         0.24140              0.10520         0.2597   \n",
      "4           0.13280         0.19800              0.10430         0.1809   \n",
      "5           0.17000         0.15780              0.08089         0.2087   \n",
      "6           0.10900         0.11270              0.07400         0.1794   \n",
      "7           0.16450         0.09366              0.05985         0.2196   \n",
      "8           0.19320         0.18590              0.09353         0.2350   \n",
      "9           0.23960         0.22730              0.08543         0.2030   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "5                 0.07613  ...          23.75           103.40       741.6   \n",
      "6                 0.05742  ...          27.66           153.20      1606.0   \n",
      "7                 0.07451  ...          28.14           110.60       897.0   \n",
      "8                 0.07389  ...          30.73           106.20       739.3   \n",
      "9                 0.08243  ...          40.68            97.65       711.4   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "5            0.1791             0.5249           0.5355                0.1741   \n",
      "6            0.1442             0.2576           0.3784                0.1932   \n",
      "7            0.1654             0.3682           0.2678                0.1556   \n",
      "8            0.1703             0.5401           0.5390                0.2060   \n",
      "9            0.1853             1.0580           1.1050                0.2210   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  labels  \n",
      "0          0.4601                  0.11890     0.0  \n",
      "1          0.2750                  0.08902     0.0  \n",
      "2          0.3613                  0.08758     0.0  \n",
      "3          0.6638                  0.17300     0.0  \n",
      "4          0.2364                  0.07678     0.0  \n",
      "5          0.3985                  0.12440     0.0  \n",
      "6          0.3063                  0.08368     0.0  \n",
      "7          0.3196                  0.11510     0.0  \n",
      "8          0.4378                  0.10720     0.0  \n",
      "9          0.4366                  0.20750     0.0  \n",
      "\n",
      "[10 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'automl': {u'blacklist': [],\n",
       "  u'folds': 3,\n",
       "  u'optimize_on': u'Accuracy',\n",
       "  u'round': 2,\n",
       "  u'silent': True,\n",
       "  u'target_variable': u'labels',\n",
       "  u'turbo': True,\n",
       "  u'verbose': False},\n",
       " u'is_classification': True}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<Add code snippet that shows the payload contents>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>For Seller to update: Ensure that file_name variable points to the payload you created. \n",
    "Ensure that output_file_name variable points to a file-name in which output of real-time inference needs to be stored.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C. Perform real-time inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>For Seller to update: review/update file_name, output_file name, custom attributes in following AWS CLI to perform a real-time inference using the payload file you created from 2.B </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"InvokedProductionVariant\": \"AllTraffic\", \r\n",
      "    \"ContentType\": \"text/csv; charset=utf-8\"\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint \\\n",
    "    --endpoint-name 'paceml-automl' \\\n",
    "    --body fileb://data/input/real-time/sample_data_automl.zip \\\n",
    "    --content-type 'application/zip' \\\n",
    "    --region us-east-2 \\\n",
    "    output.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D. Visualize output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                            Model  Accuracy   AUC  Recall  Prec.  \\\n",
      "0           0             Ada Boost Classifier      0.96  0.99    0.98   0.95   \n",
      "1           1           Extra Trees Classifier      0.96  0.99    0.98   0.96   \n",
      "2           2        Extreme Gradient Boosting      0.96  0.99    0.97   0.96   \n",
      "3           3  Light Gradient Boosting Machine      0.96  0.99    0.97   0.97   \n",
      "4           4              CatBoost Classifier      0.96  0.99    0.97   0.97   \n",
      "5           5         Random Forest Classifier      0.95  0.98    0.96   0.95   \n",
      "6           6  Quadratic Discriminant Analysis      0.95  0.99    0.95   0.97   \n",
      "7           7     Gradient Boosting Classifier      0.95  0.99    0.96   0.96   \n",
      "8           8     Linear Discriminant Analysis      0.95  0.99    0.99   0.94   \n",
      "9           9              Logistic Regression      0.94  0.99    0.96   0.94   \n",
      "\n",
      "     F1  Kappa   MCC  TT (Sec)  \n",
      "0  0.97   0.91  0.91      0.10  \n",
      "1  0.97   0.92  0.92      0.14  \n",
      "2  0.97   0.91  0.91      0.06  \n",
      "3  0.97   0.91  0.91      0.06  \n",
      "4  0.97   0.92  0.92      4.22  \n",
      "5  0.96   0.89  0.89      0.11  \n",
      "6  0.96   0.89  0.89      0.01  \n",
      "7  0.96   0.89  0.89      0.22  \n",
      "8  0.96   0.90  0.90      0.00  \n",
      "9  0.95   0.86  0.87      0.03  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "output = pd.read_csv(\"./data/output/real-time/output.csv\")\n",
    "print(output.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E. Delete the endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have successfully performed a real-time inference, you do not need the endpoint any more. You can terminate the endpoint to avoid being charged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor=sage.RealTimePredictor(model_name, sagemaker_session,content_type)\n",
    "predictor.delete_endpoint(delete_endpoint_config=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Perform batch inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, you will perform batch inference using multiple input payloads together. If you are not familiar with batch transform, and want to learn more, see these links:\n",
    "1. [How it works](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-batch-transform.html)\n",
    "2. [How to run a batch transform job](https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transform input uploaded to s3://sagemaker-us-east-2-786796469737/paceml-automl\n"
     ]
    }
   ],
   "source": [
    "#upload the batch-transform job input files to S3\n",
    "transform_input_folder = \"data/input/batch\"\n",
    "transform_input = sagemaker_session.upload_data(transform_input_folder, key_prefix=model_name) \n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................\u001b[32m2021-02-03T16:03:46.818:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[34m2021/02/03 16:03:46 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m2021/02/03 16:03:46 [crit] 13#13: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2021-02-03 16:03:46 +0000] [12] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[34m[2021-02-03 16:03:46 +0000] [12] [INFO] Listening at: unix:/tmp/gunicorn.sock (12)\u001b[0m\n",
      "\u001b[34m[2021-02-03 16:03:46 +0000] [12] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-02-03 16:03:46 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[34m[2021-02-03 16:03:46 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /ping HTTP/1.1\" 200 12 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[35m2021/02/03 16:03:46 [crit] 13#13: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m2021/02/03 16:03:46 [crit] 13#13: *3 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2021-02-03 16:03:46 +0000] [12] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
      "\u001b[35m[2021-02-03 16:03:46 +0000] [12] [INFO] Listening at: unix:/tmp/gunicorn.sock (12)\u001b[0m\n",
      "\u001b[35m[2021-02-03 16:03:46 +0000] [12] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-02-03 16:03:46 +0000] [16] [INFO] Booting worker with pid: 16\u001b[0m\n",
      "\u001b[35m[2021-02-03 16:03:46 +0000] [17] [INFO] Booting worker with pid: 17\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /ping HTTP/1.1\" 200 12 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [03/Feb/2021:16:03:46 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m11                      Naive Bayes      0.94  0.99    0.96   0.94  0.95   \u001b[0m\n",
      "\u001b[34m12           K Neighbors Classifier      0.93  0.96    0.96   0.93  0.94   \u001b[0m\n",
      "\u001b[34m13         Decision Tree Classifier      0.91  0.91    0.94   0.93  0.93   \u001b[0m\n",
      "\u001b[34m14              SVM - Linear Kernel      0.89  0.00    0.91   0.92  0.91   \n",
      "\n",
      "    Kappa   MCC  TT (Sec)  \u001b[0m\n",
      "\u001b[34m0    0.94  0.94      0.06  \u001b[0m\n",
      "\u001b[34m1    0.93  0.93      7.31  \u001b[0m\n",
      "\u001b[34m2    0.91  0.91      0.00  \u001b[0m\n",
      "\u001b[34m3    0.91  0.91      0.14  \u001b[0m\n",
      "\u001b[34m4    0.91  0.91      0.04  \u001b[0m\n",
      "\u001b[34m5    0.90  0.90      0.00  \u001b[0m\n",
      "\u001b[34m6    0.89  0.89      0.11  \u001b[0m\n",
      "\u001b[34m7    0.90  0.90      0.00  \u001b[0m\n",
      "\u001b[34m8    0.89  0.89      0.10  \u001b[0m\n",
      "\u001b[34m9    0.90  0.90      0.22  \u001b[0m\n",
      "\u001b[34m10   0.88  0.88      0.03  \u001b[0m\n",
      "\u001b[34m11   0.86  0.87      0.00  \u001b[0m\n",
      "\u001b[34m12   0.85  0.85      0.00  \u001b[0m\n",
      "\u001b[34m13   0.82  0.82      0.00  \u001b[0m\n",
      "\u001b[34m14   0.77  0.78      0.00  \u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [03/Feb/2021:16:04:17 +0000] \"POST /invocations HTTP/1.1\" 200 1027 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m11                      Naive Bayes      0.94  0.99    0.96   0.94  0.95   \u001b[0m\n",
      "\u001b[35m12           K Neighbors Classifier      0.93  0.96    0.96   0.93  0.94   \u001b[0m\n",
      "\u001b[35m13         Decision Tree Classifier      0.91  0.91    0.94   0.93  0.93   \u001b[0m\n",
      "\u001b[35m14              SVM - Linear Kernel      0.89  0.00    0.91   0.92  0.91   \n",
      "\n",
      "    Kappa   MCC  TT (Sec)  \u001b[0m\n",
      "\u001b[35m0    0.94  0.94      0.06  \u001b[0m\n",
      "\u001b[35m1    0.93  0.93      7.31  \u001b[0m\n",
      "\u001b[35m2    0.91  0.91      0.00  \u001b[0m\n",
      "\u001b[35m3    0.91  0.91      0.14  \u001b[0m\n",
      "\u001b[35m4    0.91  0.91      0.04  \u001b[0m\n",
      "\u001b[35m5    0.90  0.90      0.00  \u001b[0m\n",
      "\u001b[35m6    0.89  0.89      0.11  \u001b[0m\n",
      "\u001b[35m7    0.90  0.90      0.00  \u001b[0m\n",
      "\u001b[35m8    0.89  0.89      0.10  \u001b[0m\n",
      "\u001b[35m9    0.90  0.90      0.22  \u001b[0m\n",
      "\u001b[35m10   0.88  0.88      0.03  \u001b[0m\n",
      "\u001b[35m11   0.86  0.87      0.00  \u001b[0m\n",
      "\u001b[35m12   0.85  0.85      0.00  \u001b[0m\n",
      "\u001b[35m13   0.82  0.82      0.00  \u001b[0m\n",
      "\u001b[35m14   0.77  0.78      0.00  \u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [03/Feb/2021:16:04:17 +0000] \"POST /invocations HTTP/1.1\" 200 1027 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run the batch-transform job\n",
    "transformer = model.transformer(1, batch_transform_inference_instance_type)\n",
    "transformer.transform(transform_input, content_type=content_type)\n",
    "transformer.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-2-786796469737/paceml-automl-2021-02-03-15-45-41-550-2021-02-03-16-00-10-674'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#output is available on following path\n",
    "transformer.output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output file loaded from bucket\n"
     ]
    }
   ],
   "source": [
    "s3_conn = boto3.client(\"s3\")\n",
    "bucket_name=\"bucket-name\"\n",
    "with open('./data/output/batch/output.csv', 'wb') as f:\n",
    "    s3_conn.download_fileobj(bucket_name, 'folder-name'+'/sample_data_automl.zip.out', f)\n",
    "    print(\"Output file loaded from bucket\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                            Model  Accuracy   AUC  Recall  Prec.  \\\n",
      "0           0  Light Gradient Boosting Machine      0.97  0.99    0.98   0.97   \n",
      "1           1              CatBoost Classifier      0.97  1.00    0.98   0.96   \n",
      "2           2     Linear Discriminant Analysis      0.96  0.99    0.99   0.95   \n",
      "3           3           Extra Trees Classifier      0.96  0.99    0.97   0.96   \n",
      "4           4        Extreme Gradient Boosting      0.96  0.99    0.97   0.97   \n",
      "5           5                 Ridge Classifier      0.95  0.00    0.99   0.94   \n",
      "6           6         Random Forest Classifier      0.95  0.99    0.95   0.97   \n",
      "7           7  Quadratic Discriminant Analysis      0.95  0.99    0.95   0.97   \n",
      "8           8             Ada Boost Classifier      0.95  0.99    0.96   0.96   \n",
      "9           9     Gradient Boosting Classifier      0.95  0.99    0.97   0.95   \n",
      "\n",
      "     F1  Kappa   MCC  TT (Sec)  \n",
      "0  0.98   0.94  0.94      0.06  \n",
      "1  0.97   0.93  0.93      7.31  \n",
      "2  0.97   0.91  0.91      0.00  \n",
      "3  0.97   0.91  0.91      0.14  \n",
      "4  0.97   0.91  0.91      0.04  \n",
      "5  0.96   0.90  0.90      0.00  \n",
      "6  0.96   0.89  0.89      0.11  \n",
      "7  0.96   0.90  0.90      0.00  \n",
      "8  0.96   0.89  0.89      0.10  \n",
      "9  0.96   0.90  0.90      0.22  \n"
     ]
    }
   ],
   "source": [
    "output_df = pd.read_csv(\"./data/output/batch/output.csv\")\n",
    "#print(output.read())\n",
    "print(output_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A. Delete the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B. Unsubscribe to the listing (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to unsubscribe to the model package, follow these steps. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model. \n",
    "\n",
    "**Steps to unsubscribe to product from AWS Marketplace**:\n",
    "1. Navigate to __Machine Learning__ tab on [__Your Software subscriptions page__](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=mlmp_gitdemo_indust)\n",
    "2. Locate the listing that you want to cancel the subscription for, and then choose __Cancel Subscription__  to cancel the subscription.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
